{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BreastData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': '/srv/conda/lib/python3.6/site-packages/sklearn/datasets/data/breast_cancer.csv'}\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#----------------------------------------------------\n",
    "\n",
    "#load breast cancer data\n",
    "\n",
    "BreastData = load_breast_cancer()\n",
    "\n",
    "#X Data\n",
    "X = BreastData.data\n",
    "\n",
    "#y Data\n",
    "y = BreastData.target\n",
    "print (BreastData)\n",
    "#print (BreastData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = \n",
      "  [[1.245e+01 1.570e+01 8.257e+01 ... 1.741e-01 3.985e-01 1.244e-01]\n",
      " [1.152e+01 1.875e+01 7.334e+01 ... 6.316e-02 3.306e-01 7.036e-02]\n",
      " [1.940e+01 1.818e+01 1.272e+02 ... 2.252e-01 3.590e-01 7.787e-02]\n",
      " ...\n",
      " [1.218e+01 1.784e+01 7.779e+01 ... 5.882e-02 2.227e-01 7.376e-02]\n",
      " [1.108e+01 1.471e+01 7.021e+01 ... 4.306e-02 1.902e-01 7.313e-02]\n",
      " [1.116e+01 2.141e+01 7.095e+01 ... 4.306e-02 2.976e-01 7.123e-02]]\n",
      "########################################\n",
      "X_train shape= \n",
      "  (381, 30)\n",
      "########################################\n",
      "y_train = \n",
      "  [0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1\n",
      " 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0\n",
      " 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0\n",
      " 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1\n",
      " 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1\n",
      " 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1]\n",
      "########################################\n",
      "y_train shape= \n",
      "  (381,)\n",
      "########################################\n",
      "X_test = \n",
      "  [[1.328e+01 2.028e+01 8.732e+01 ... 1.492e-01 3.739e-01 1.027e-01]\n",
      " [2.059e+01 2.124e+01 1.378e+02 ... 2.113e-01 2.480e-01 8.999e-02]\n",
      " [1.218e+01 2.052e+01 7.722e+01 ... 7.431e-02 2.694e-01 6.878e-02]\n",
      " ...\n",
      " [1.231e+01 1.652e+01 7.919e+01 ... 8.660e-02 2.618e-01 7.609e-02]\n",
      " [1.422e+01 2.785e+01 9.255e+01 ... 8.219e-02 1.890e-01 7.796e-02]\n",
      " [1.917e+01 2.480e+01 1.324e+02 ... 1.767e-01 3.176e-01 1.023e-01]]\n",
      "########################################\n",
      "X_test shape= \n",
      "  (188, 30)\n",
      "########################################\n",
      "y_test = \n",
      "  [0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1\n",
      " 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0\n",
      " 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1\n",
      " 1 1 0]\n",
      "########################################\n",
      "y_test= \n",
      "  (188,)\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "#Splitting data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n",
    "\n",
    "print('X_train = \\n ',X_train)\n",
    "print('########################################')\n",
    "print('X_train shape= \\n ',X_train.shape)\n",
    "print('########################################')\n",
    "print('y_train = \\n ',y_train)\n",
    "print('########################################')\n",
    "print('y_train shape= \\n ',y_train.shape)\n",
    "print('########################################')\n",
    "print('X_test = \\n ',X_test)\n",
    "print('########################################')\n",
    "print('X_test shape= \\n ',X_test.shape)\n",
    "print('########################################')\n",
    "print('y_test = \\n ',y_test)\n",
    "print('########################################')\n",
    "print('y_test= \\n ',y_test.shape)\n",
    "print('########################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionModel Train Score is :  0.889763779527559\n",
      "LogisticRegressionModel Test Score is :  0.9414893617021277\n",
      "LogisticRegressionModel Classes are :  [0 1]\n",
      "LogisticRegressionModel No. of iteratios is :  [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Applying LogisticRegression Model \n",
    "\n",
    "'''\n",
    "#linear_model.LogisticRegression(penalty='l2’,dual=False,tol=0.0001,C=1.0,fit_intercept=True,intercept_scaling=1,\n",
    "#                                class_weight=None,random_state=None,solver='warn’,max_iter=100,\n",
    "#                                multi_class='warn’, verbose=0,warm_start=False, n_jobs=None)\n",
    "'''\n",
    "\n",
    "LogisticRegressionModel = LogisticRegression(penalty='l2',solver='sag',C=1.0,random_state=33)\n",
    "LogisticRegressionModel.fit(X_train, y_train)\n",
    "\n",
    "#Calculating Details\n",
    "print('LogisticRegressionModel Train Score is : ' , LogisticRegressionModel.score(X_train, y_train))\n",
    "print('LogisticRegressionModel Test Score is : ' , LogisticRegressionModel.score(X_test, y_test))\n",
    "print('LogisticRegressionModel Classes are : ' , LogisticRegressionModel.classes_)\n",
    "print('LogisticRegressionModel No. of iteratios is : ' , LogisticRegressionModel.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value for LogisticRegressionModel is : \n",
      "   [0 0 1 0 1 1 1 1 0 1]\n",
      "Prediction Probabilities Value for LogisticRegressionModel is  : \n",
      "  [[9.42584502e-01 5.74154975e-02]\n",
      " [9.61625154e-01 3.83748458e-02]\n",
      " [1.73159164e-01 8.26840836e-01]\n",
      " [9.99820175e-01 1.79825490e-04]\n",
      " [2.94009572e-01 7.05990428e-01]\n",
      " [3.42113923e-01 6.57886077e-01]\n",
      " [1.41784010e-01 8.58215990e-01]\n",
      " [2.45404097e-01 7.54595903e-01]\n",
      " [7.43483833e-01 2.56516167e-01]\n",
      " [1.81340441e-01 8.18659559e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating Prediction\n",
    "y_pred = LogisticRegressionModel.predict(X_test)\n",
    "y_pred_prob = LogisticRegressionModel.predict_proba(X_test)\n",
    "print('Predicted Value for LogisticRegressionModel is : \\n  ' , y_pred[:10])\n",
    "print('Prediction Probabilities Value for LogisticRegressionModel is  : \\n ' , y_pred_prob[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is : \n",
      " [[ 59   9]\n",
      " [  2 118]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating Confusion Matrix\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix is : \\n', CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 21.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /srv/conda/lib/python3.6/site-packages (from seaborn) (1.16.3)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /srv/conda/lib/python3.6/site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /srv/conda/lib/python3.6/site-packages (from seaborn) (3.0.3)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /srv/conda/lib/python3.6/site-packages (from seaborn) (0.24.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /srv/conda/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /srv/conda/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /srv/conda/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2019.1)\n",
      "Requirement already satisfied: six in /srv/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=1.4.3->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /srv/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.8.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(CM, center = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is :  177\n"
     ]
    }
   ],
   "source": [
    "#Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))\n",
    "AccScore = accuracy_score(y_test, y_pred, normalize=False)\n",
    "print('Accuracy Score is : ', AccScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is :  0.9414893617021277\n"
     ]
    }
   ],
   "source": [
    "#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)\n",
    "# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "\n",
    "F1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('F1 Score is : ', F1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score is :  0.9414893617021277\n"
     ]
    }
   ],
   "source": [
    "#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  \n",
    "# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n",
    "\n",
    "RecallScore = recall_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Recall Score is : ', RecallScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score is :  0.9414893617021277\n"
     ]
    }
   ],
   "source": [
    "#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  \n",
    "# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)\n",
    "\n",
    "PrecisionScore = precision_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Precision Score is : ', PrecisionScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Recall Score is :  (0.9414893617021277, 0.9414893617021277, 0.9414893617021277, None)\n"
     ]
    }
   ],
   "source": [
    "#Calculating Precision recall Score :  \n",
    "#metrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1, average=\n",
    "#                                        None, warn_for = ('precision’,’recall’, ’f-score’), sample_weight=None)\n",
    "\n",
    "PrecisionRecallScore = precision_recall_fscore_support(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\n",
    "print('Precision Recall Score is : ', PrecisionRecallScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Value is :  [0.63829787 0.92913386 1.        ]\n",
      "Recall Value is :  [1.         0.98333333 0.        ]\n",
      "Thresholds Value is :  [0 1]\n"
     ]
    }
   ],
   "source": [
    "#Calculating Precision recall Curve :  \n",
    "# precision_recall_curve(y_true, probas_pred, pos_label=None, sample_weight=None)\n",
    "\n",
    "PrecisionValue, RecallValue, ThresholdsValue = precision_recall_curve(y_test,y_pred)\n",
    "print('Precision Value is : ', PrecisionValue)\n",
    "print('Recall Value is : ', RecallValue)\n",
    "print('Thresholds Value is : ', ThresholdsValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report is : \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.91        68\n",
      "           1       0.93      0.98      0.96       120\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       188\n",
      "   macro avg       0.95      0.93      0.94       188\n",
      "weighted avg       0.94      0.94      0.94       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating classification Report :  \n",
    "#classification_report(y_true, y_pred, labels=None, target_names=None,sample_weight=None, digits=2, output_dict=False)\n",
    "\n",
    "ClassificationReport = classification_report(y_test,y_pred)\n",
    "print('Classification Report is : \\n ', ClassificationReport )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Value  :  0.9254901960784314\n"
     ]
    }
   ],
   "source": [
    "#Calculating Area Under the Curve :  \n",
    "\n",
    "fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)\n",
    "AUCValue = auc(fprValue2, tprValue2)\n",
    "print('AUC Value  : ', AUCValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr Value  :  [0.         0.13235294 1.        ]\n",
      "tpr Value  :  [0.         0.98333333 1.        ]\n",
      "thresholds Value  :  [2 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Calculating Receiver Operating Characteristic :  \n",
    "#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)\n",
    "\n",
    "fprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred)\n",
    "print('fpr Value  : ', fprValue)\n",
    "print('tpr Value  : ', tprValue)\n",
    "print('thresholds Value  : ', thresholdsValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC Score :  0.9254901960784314\n"
     ]
    }
   ],
   "source": [
    "#Calculating ROC AUC Score:  \n",
    "#roc_auc_score(y_true, y_score, average=’macro’, sample_weight=None,max_fpr=None)\n",
    "\n",
    "ROCAUCScore = roc_auc_score(y_test,y_pred, average='micro') #it can be : macro,weighted,samples\n",
    "print('ROCAUC Score : ', ROCAUCScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero One Loss Value :  11\n"
     ]
    }
   ],
   "source": [
    "#Calculating Zero One Loss:  \n",
    "#zero_one_loss(y_true, y_pred, normalize = True, sample_weight = None)\n",
    "\n",
    "ZeroOneLossValue = zero_one_loss(y_test,y_pred,normalize=False) \n",
    "print('Zero One Loss Value : ', ZeroOneLossValue )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
